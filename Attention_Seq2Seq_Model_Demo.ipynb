{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import AttentionSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size: 36\n",
      "Target Vocabulary Size: 36\n"
     ]
    }
   ],
   "source": [
    "maximum_src_str_len = 40\n",
    "maximum_tgt_str_len = 40\n",
    "source_vocab_size = -1\n",
    "target_vocab_size = -1\n",
    "\n",
    "_PAD = \"_PAD\"\n",
    "_GO = \"_GO\"\n",
    "_EOS = \"_EOS\"\n",
    "\n",
    "input_str = \"I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\"\n",
    "target_str =\"Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.\"\n",
    "\n",
    "def input_process(input_str):\n",
    "    input_str = input_str[:-1] + \" \" + _EOS\n",
    "    for i in range(maximum_src_str_len-len(input_str.split(\" \"))):\n",
    "        input_str += \" \" + _PAD\n",
    "    return input_str\n",
    "\n",
    "def target_process(target_str):\n",
    "    target_str = _GO + \" \" + target_str[:-1]\n",
    "    target_str = target_str + \" \" + _EOS\n",
    "    for i in range(maximum_tgt_str_len-len(target_str.split(\" \"))):\n",
    "        target_str += \" \" + _PAD\n",
    "    return target_str\n",
    "    \n",
    "input_str_list = [input_process(input_str)]\n",
    "target_str_list = [target_process(target_str)]\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "source_vocab_processor = learn.preprocessing.VocabularyProcessor(maximum_src_str_len)\n",
    "input_data = np.array(list(source_vocab_processor.fit_transform(input_str_list)))\n",
    "source_vocab_size = len(source_vocab_processor.vocabulary_)\n",
    "print(\"Source Vocabulary Size: {:d}\".format(len(source_vocab_processor.vocabulary_)))\n",
    "\n",
    "target_vocab_processor = learn.preprocessing.VocabularyProcessor(maximum_tgt_str_len)\n",
    "target_data = np.array(list(target_vocab_processor.fit_transform(target_str_list)))\n",
    "target_vocab_size = len(target_vocab_processor.vocabulary_)\n",
    "print(\"Target Vocabulary Size: {:d}\".format(len(target_vocab_processor.vocabulary_)))\n",
    "\n",
    "source_vocab_dict = source_vocab_processor.vocabulary_._mapping\n",
    "target_vocab_dict = target_vocab_processor.vocabulary_._mapping\n",
    "source_vocab_rev_dict = source_vocab_processor.vocabulary_._reverse_mapping\n",
    "target_vocab_rev_dict = target_vocab_processor.vocabulary_._reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data    = input_data.tolist()[0]\n",
    "target_data   = target_data.tolist()[0]\n",
    "label_data = [target_data[i+1] for i in range(len(target_data) - 1)] + [target_vocab_dict[_PAD]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_batch = []\n",
    "target_batch = []\n",
    "label_batch = []\n",
    "\n",
    "for _ in range(100):\n",
    "    input_batch.append(input_data)\n",
    "    target_batch.append(target_data)\n",
    "    label_batch.append(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(bytes):\n",
    "    sentence_marks = [0, target_vocab_dict[\"_PAD\"], target_vocab_dict[\"_EOS\"], target_vocab_dict[\"_GO\"]]\n",
    "    word = \"\"\n",
    "    \n",
    "    for b in bytes:\n",
    "        if not b[0] in sentence_marks:\n",
    "            word += \" \" + target_vocab_rev_dict[b[0]]\n",
    "    word += \".\"\n",
    "    return word[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder/embeddings\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_0_step/rnn/transpose\n",
      "decoder_0_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_1_step/rnn/transpose\n",
      "decoder_1_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_2_step/rnn/transpose\n",
      "decoder_2_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_3_step/rnn/transpose\n",
      "decoder_3_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_4_step/rnn/transpose\n",
      "decoder_4_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_5_step/rnn/transpose\n",
      "decoder_5_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_6_step/rnn/transpose\n",
      "decoder_6_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_7_step/rnn/transpose\n",
      "decoder_7_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_8_step/rnn/transpose\n",
      "decoder_8_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_9_step/rnn/transpose\n",
      "decoder_9_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_10_step/rnn/transpose\n",
      "decoder_10_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_11_step/rnn/transpose\n",
      "decoder_11_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_12_step/rnn/transpose\n",
      "decoder_12_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_13_step/rnn/transpose\n",
      "decoder_13_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_14_step/rnn/transpose\n",
      "decoder_14_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_15_step/rnn/transpose\n",
      "decoder_15_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_16_step/rnn/transpose\n",
      "decoder_16_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_17_step/rnn/transpose\n",
      "decoder_17_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_18_step/rnn/transpose\n",
      "decoder_18_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_19_step/rnn/transpose\n",
      "decoder_19_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_20_step/rnn/transpose\n",
      "decoder_20_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_21_step/rnn/transpose\n",
      "decoder_21_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_22_step/rnn/transpose\n",
      "decoder_22_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_23_step/rnn/transpose\n",
      "decoder_23_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_24_step/rnn/transpose\n",
      "decoder_24_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_25_step/rnn/transpose\n",
      "decoder_25_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_26_step/rnn/transpose\n",
      "decoder_26_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_27_step/rnn/transpose\n",
      "decoder_27_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_28_step/rnn/transpose\n",
      "decoder_28_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_29_step/rnn/transpose\n",
      "decoder_29_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_30_step/rnn/transpose\n",
      "decoder_30_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_31_step/rnn/transpose\n",
      "decoder_31_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_32_step/rnn/transpose\n",
      "decoder_32_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_33_step/rnn/transpose\n",
      "decoder_33_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_34_step/rnn/transpose\n",
      "decoder_34_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_35_step/rnn/transpose\n",
      "decoder_35_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_36_step/rnn/transpose\n",
      "decoder_36_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_37_step/rnn/transpose\n",
      "decoder_37_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_38_step/rnn/transpose\n",
      "decoder_38_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_39_step/rnn/transpose\n",
      "decoder_39_step/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "decoder/embeddings\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_0_step_1/rnn/transpose\n",
      "decoder_0_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_1_step_1/rnn/transpose\n",
      "decoder_1_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_2_step_1/rnn/transpose\n",
      "decoder_2_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_3_step_1/rnn/transpose\n",
      "decoder_3_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_4_step_1/rnn/transpose\n",
      "decoder_4_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_5_step_1/rnn/transpose\n",
      "decoder_5_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_6_step_1/rnn/transpose\n",
      "decoder_6_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_7_step_1/rnn/transpose\n",
      "decoder_7_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_8_step_1/rnn/transpose\n",
      "decoder_8_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_9_step_1/rnn/transpose\n",
      "decoder_9_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_10_step_1/rnn/transpose\n",
      "decoder_10_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_11_step_1/rnn/transpose\n",
      "decoder_11_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_12_step_1/rnn/transpose\n",
      "decoder_12_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_13_step_1/rnn/transpose\n",
      "decoder_13_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_14_step_1/rnn/transpose\n",
      "decoder_14_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_15_step_1/rnn/transpose\n",
      "decoder_15_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_16_step_1/rnn/transpose\n",
      "decoder_16_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_17_step_1/rnn/transpose\n",
      "decoder_17_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_18_step_1/rnn/transpose\n",
      "decoder_18_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_19_step_1/rnn/transpose\n",
      "decoder_19_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_20_step_1/rnn/transpose\n",
      "decoder_20_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_21_step_1/rnn/transpose\n",
      "decoder_21_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_22_step_1/rnn/transpose\n",
      "decoder_22_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_23_step_1/rnn/transpose\n",
      "decoder_23_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_24_step_1/rnn/transpose\n",
      "decoder_24_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_25_step_1/rnn/transpose\n",
      "decoder_25_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_26_step_1/rnn/transpose\n",
      "decoder_26_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_27_step_1/rnn/transpose\n",
      "decoder_27_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_28_step_1/rnn/transpose\n",
      "decoder_28_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_29_step_1/rnn/transpose\n",
      "decoder_29_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_30_step_1/rnn/transpose\n",
      "decoder_30_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_31_step_1/rnn/transpose\n",
      "decoder_31_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_32_step_1/rnn/transpose\n",
      "decoder_32_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_33_step_1/rnn/transpose\n",
      "decoder_33_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_34_step_1/rnn/transpose\n",
      "decoder_34_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_35_step_1/rnn/transpose\n",
      "decoder_35_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_36_step_1/rnn/transpose\n",
      "decoder_36_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_37_step_1/rnn/transpose\n",
      "decoder_37_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_38_step_1/rnn/transpose\n",
      "decoder_38_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "attention/W_a\n",
      "attention/U_a\n",
      "attention/v_a\n",
      "attention/b\n",
      "decoder_39_step_1/rnn/transpose\n",
      "decoder_39_step_1/rnn/while/Exit_2\n",
      "decoder/fully_connected_weight\n",
      "Average loss at step  0 :  3.58013\n",
      "Predicted sentence :  tous espérant je la je du Parlement Parlement Parlement je déclare le le qui décembre décembre de décembre vous vous vous vous vous tous avez 17 17 avez vous.\n",
      "Average loss at step  1 :  2.8063\n",
      "Predicted sentence :  tous déclare la la du du européen européen qui avait le le le vendredi décembre décembre dernier je vous vous vous vous vous vux en vous vous avez 17 de bonnes vacances vous.\n",
      "Average loss at step  2 :  1.9721\n",
      "Predicted sentence :  la déclare la la du du européen européen qui avait interrompue le le vendredi décembre décembre dernier et vous vous vous vous en vux en je vous avez 17 de bonnes vacances.\n",
      "Average loss at step  3 :  1.51191\n",
      "Predicted sentence :  reprise déclare déclare la du du Parlement européen qui avait été le le vendredi décembre décembre dernier et je vous vous vous vux vux en je que vous avez passé de bonnes vacances.\n",
      "Average loss at step  4 :  1.15924\n",
      "Predicted sentence :  vacances déclare reprise la session du Parlement européen qui avait été interrompue le vendredi décembre décembre dernier et je vous renouvelle vous en vux en je que vous avez vous de bonnes vacances.\n",
      "Average loss at step  5 :  0.900665\n",
      "Predicted sentence :  Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle vous mes vux en je que vous avez passé de bonnes vacances.\n",
      "Average loss at step  6 :  0.693422\n",
      "Predicted sentence :  Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et espérant vous renouvelle vous mes vux en espérant que vous avez passé de bonnes vacances.\n",
      "Average loss at step  7 :  0.531731\n",
      "Predicted sentence :  Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et espérant vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.\n",
      "Average loss at step  8 :  0.416343\n",
      "Predicted sentence :  Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.\n",
      "Matched!!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "batch_size = 100\n",
    "enc_sequence_len = maximum_src_str_len\n",
    "dec_sequence_len = maximum_tgt_str_len\n",
    "enc_symbol_size = source_vocab_size\n",
    "dec_symbol_size = target_vocab_size\n",
    "embedding_size = 10\n",
    "hidden_size = 10\n",
    "layer_size = 1\n",
    "\n",
    "model = AttentionSeq2Seq(sess,\n",
    "                         batch_size,\n",
    "                         enc_sequence_len, \n",
    "                         dec_sequence_len,\n",
    "                         enc_symbol_size,\n",
    "                         dec_symbol_size,\n",
    "                         embedding_size,\n",
    "                         hidden_size)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "go_signal = []\n",
    "for _ in range(batch_size):\n",
    "    go_signal.append([target_vocab_dict[_GO]])\n",
    "\n",
    "for step in range(500):\n",
    "    loss, _ = model.train(input_batch, target_batch, label_batch)\n",
    "    print(\"Average loss at step \", step, \": \", loss)\n",
    "    pred = model.prediction(input_batch, go_signal)\n",
    "    pred_sentence = decode(pred[0])\n",
    "    print('Predicted sentence : ', pred_sentence)\n",
    "    if pred_sentence == target_str:\n",
    "        print(\"Matched!!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 실험 결과….\n",
    "\n",
    "원래 : Je déclare reprise la(session)(du)Parlement européen qui avait été interrompue le vendredi 17 décembre(dernier)et je vous (renouvelle)tous mes vux en espérant que vous avez passé  (de)  bonnes vacances.\n",
    "예측 : Je déclare reprise la <UNK> <UNK> Parlement européen qui avait été interrompue le vendredi 17 décembre <UNK> et je  vous     <UNK>   tous mes vux en espérant que vous avez passé <UNK> bonnes vacances _EOS _PAD _PAD _PAD _PAD _PAD _PAD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
